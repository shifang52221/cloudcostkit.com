---
import GuideLayout from "../../layouts/GuideLayout.astro";

const title = "Load balancer cost optimization (high-leverage fixes)";
const description =
  "A practical playbook to reduce load balancer costs: cut LB-hours, reduce LCU/NLCU drivers (connections/bytes/requests), and prevent incident traffic amplification with a measurable validation plan.";
const faqs = [
  {
    q: "What's the fastest lever for load balancer cost?",
    a: "Reduce LB-hours by reducing the number of load balancers. In Kubernetes, one load balancer per service patterns create many always-on LBs.",
  },
  {
    q: "How do I reduce LCU/NLCU charges?",
    a: "Reduce the drivers: connection churn, active connections, bytes processed, and rule evaluation overhead. Fix retry storms and chatty clients that multiply traffic.",
  },
  {
    q: "Should I optimize LB-hours or LCUs first?",
    a: "If you have many LBs, start with LB-hours. If you have a few high-traffic LBs, focus on LCU/NLCU and the traffic drivers.",
  },
  {
    q: "Why do load balancer bills spike during incidents?",
    a: "Retries and timeouts can multiply requests and connections. Bot traffic and thundering herds can inflate bytes processed even when success traffic is flat.",
  },
];
---
<GuideLayout
  title={title}
  description={description}
  canonicalPath="/guides/aws-load-balancer-cost-optimization"
  lastUpdated="2026-02-07"
  faqs={faqs}
>
  <p>
    Load balancer optimization is usually about two levers: <strong>how many LBs you run</strong> (LB-hours) and{" "}
    <strong>how busy each LB is</strong> (LCU/NLCU). The best results come from reducing always-on LB count and removing
    traffic amplification patterns that inflate connections and bytes.
  </p>

  <h2>Fast optimization checks</h2>
  <ul>
    <li><strong>Consolidate</strong>: reduce one-LB-per-service patterns.</li>
    <li><strong>Cross-zone</strong>: disable when safe to reduce cross-AZ transfer.</li>
    <li><strong>Idle LBs</strong>: remove unused listeners and test environments.</li>
  </ul>


  <h2>Step 1: reduce the number of load balancers (LB-hours)</h2>
  <ul>
    <li>
      Consolidate services behind shared ingress where feasible (especially in Kubernetes).
    </li>
    <li>
      Delete abandoned LBs from migrations and experiments (they often remain “quietly expensive”).
    </li>
    <li>
      Standardize patterns: “one public LB per environment” is usually cheaper than “one per microservice”.
    </li>
  </ul>
  <p class="muted">
    Start by listing all LBs and tagging ownership; cost reduction is often “delete what nobody owns”.
  </p>

  <h2>Step 2: reduce LCU/NLCU drivers (requests, connections, bytes)</h2>
  <ul>
    <li>
      <strong>Reduce connection churn</strong>: keep-alive and fewer short timeouts reduce new connections.
    </li>
    <li>
      <strong>Reduce bytes processed</strong>: compress payloads, avoid routing large downloads through the LB, offload to CDN/object storage.
    </li>
    <li>
      <strong>Reduce request amplification</strong>: cache hot responses and avoid “polling every second” patterns.
    </li>
    <li>
      <strong>Simplify routing rules</strong>: avoid unnecessary rule complexity that adds evaluation overhead.
    </li>
  </ul>
  <p class="muted">
    If you can’t tell which driver dominates, run the LCU estimator from metrics and look at which dimension is highest:
    <a href="/guides/aws-load-balancer-estimate-lcu/"> estimate LCU/NLCU</a>.
  </p>

  <h2>Step 3: remove incident multipliers (the most common “spike” root cause)</h2>
  <ul>
    <li>
      Fix retry storms: set sane timeouts, jittered backoff, and circuit breakers for downstream outages.
    </li>
    <li>
      Rate-limit abusive clients and bot traffic (a small amount of unwanted traffic can dominate LCU).
    </li>
    <li>
      Watch for deploy storms: rolling deploys can temporarily multiply connections and error retries.
    </li>
  </ul>

  <h2>Step 4: quantify savings before changing architecture</h2>
  <p>
    Optimization gets easier when you model the before/after in the same terms:
  </p>
  <ul>
    <li>
      LB-hours saved = LBs removed × 730 hours/month (or your scheduled hours)
    </li>
    <li>
      Usage saved = (avg LCU/NLCU before − after) × hours/month
    </li>
  </ul>
  <div class="btn-row">
    <a class="btn" href="/calculators/aws-load-balancer-cost-calculator/">LB cost calculator</a>
    <a class="btn" href="/calculators/aws-load-balancer-lcu-calculator/">LCU/NLCU calculator</a>
    <a class="btn" href="/calculators/unit-converter/">Units converter</a>
  </div>

  <h2>Validation plan (what to measure for a week)</h2>
  <ul>
    <li>LB count and hours (did LB-hours actually drop?)</li>
    <li>LCU/NLCU drivers (connections, bytes, rule evals) for avg and p95</li>
    <li>Incident windows: did retries and errors drop after fixes?</li>
    <li>Related side effects: cross-AZ transfer and NAT/egress if routing changed</li>
  </ul>
  <p class="muted">
    Related cost domains: <a href="/guides/aws-nat-gateway-cost/">NAT gateway costs</a> and{" "}
    <a href="/guides/aws-vpc-data-transfer/">VPC data transfer</a>.
  </p>

  <h2>Sources</h2>
  <ul>
    <li>
      <a href="https://aws.amazon.com/elasticloadbalancing/pricing/" target="_blank" rel="nofollow noopener">
        Elastic Load Balancing pricing
      </a>
    </li>
    <li>
      <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html" target="_blank" rel="nofollow noopener">
        ALB CloudWatch metrics
      </a>
    </li>
  </ul>
</GuideLayout>
