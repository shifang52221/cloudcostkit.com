---
import GuideLayout from "../../layouts/GuideLayout.astro";

const title = "Load balancer LCU/NLCU explained (for cost estimates)";
const description =
  "A practical explanation of LCU/NLCU billing: what capacity unit-hours represent, which traffic patterns drive them, and how to reason about budgets before you have perfect metrics.";
const faqs = [
  {
    q: "What is an LCU/NLCU?",
    a: "A capacity unit is a provider-defined measure of load balancer usage. Billing is commonly per unit-hour and is driven by dimensions like connections and bytes processed.",
  },
  {
    q: "Why is capacity unit billing confusing?",
    a: "Because it’s not just request count. Two systems with the same RPS can have very different unit-hours based on payload size, connection churn, long-lived connections, and rule/routing behavior.",
  },
  {
    q: "How do I estimate unit-hours without perfect observability?",
    a: "Start from a few measurable drivers (connections/sec, active connections, GB/hour). Build an average + peak scenario, then validate and replace assumptions with metrics after a week.",
  },
];
---
<GuideLayout
  title={title}
  description={description}
  canonicalPath="/guides/aws-load-balancer-lcu-explained"
  lastUpdated="2026-01-27"
  faqs={faqs}
>
  <p>
    Many load balancers charge (1) a fixed hourly fee plus (2) a usage fee billed in capacity unit-hours. For budgeting,
    you don’t need perfect precision—you need a defendable <strong>average units/hour</strong> and a <strong>peak
    scenario</strong> so incident hours don’t blow up the plan.
  </p>

  <h2>What “capacity unit-hours” means</h2>
  <p>
    Think of LCU/NLCU as a normalized “how busy was this load balancer this hour?” score. The unit is typically derived
    from multiple dimensions, and the billed unit-hours often follow the <strong>maximum</strong> of those dimensions.
  </p>
  <ul>
    <li><strong>Connections</strong>: new connections and/or active connections</li>
    <li><strong>Bytes processed</strong>: traffic volume through the LB</li>
    <li><strong>Request processing</strong>: rules/routing work (depends on product and configuration)</li>
  </ul>

  <h2>Why the same RPS can produce very different unit-hours</h2>
  <ul>
    <li>
      <strong>Payload size</strong>: 1kB responses vs 1MB downloads are not comparable.
    </li>
    <li>
      <strong>Connection churn</strong>: short timeouts and frequent reconnects inflate new connections.
    </li>
    <li>
      <strong>Long-lived connections</strong>: streaming/WebSockets increase active connections.
    </li>
    <li>
      <strong>Incidents</strong>: retries can multiply requests and connections without increasing “real” business volume.
    </li>
  </ul>

  <h2>A practical mental model for optimization</h2>
  <ul>
    <li>
      If you have <strong>many LBs</strong>, LB-hours dominate: reduce load balancer count.
    </li>
    <li>
      If you have <strong>a few hot LBs</strong>, unit-hours dominate: reduce bytes processed and connection churn.
    </li>
    <li>
      If you have <strong>spikes</strong>, the “peak scenario” dominates: fix retries and bot traffic.
    </li>
  </ul>
  <p class="muted">
    Optimization playbook: <a href="/guides/aws-load-balancer-cost-optimization/">load balancer cost optimization</a>
  </p>

  <h2>How to estimate units/hour (without getting lost)</h2>
  <ol>
    <li>Pick a representative week and a peak definition (p95 hour or incident hour).</li>
    <li>Collect driver metrics: new connections/sec, active connections, bytes processed GB/hour.</li>
    <li>Use a calculator to convert driver metrics to units/hour.</li>
    <li>Price units/hour + fixed LB hourly fee, then validate after a week.</li>
  </ol>
  <div class="btn-row">
    <a class="btn" href="/guides/aws-load-balancer-estimate-lcu/">Estimate LCU/NLCU from metrics</a>
    <a class="btn" href="/calculators/aws-load-balancer-lcu-calculator/">LCU/NLCU calculator</a>
    <a class="btn" href="/calculators/aws-load-balancer-cost-calculator/">LB cost calculator</a>
  </div>

  <h2>Common pitfalls</h2>
  <ul>
    <li>Budgeting from peak unit-hours for the whole month (hides the real average).</li>
    <li>Ignoring payload size and estimating from requests only.</li>
    <li>Missing retry storms and noisy clients as the “hidden multiplier”.</li>
    <li>Mixing units (GB vs GiB, bits vs bytes) and silently breaking the estimate.</li>
    <li>Not re-checking after architecture changes (CDN, compression, routing).</li>
  </ul>

  <h2>Quick diagnostic: which driver is dominating?</h2>
  <p>
    When you look at a week of metrics, one driver is usually “the max” most of the time. You can often predict the
    culprit from traffic shape:
  </p>
  <ul>
    <li><strong>Bytes dominate</strong>: large responses, downloads, missing compression, no CDN offload.</li>
    <li><strong>New connections dominate</strong>: short timeouts, clients reconnecting, lack of keep-alive.</li>
    <li><strong>Active connections dominate</strong>: streaming, long polling, WebSockets.</li>
    <li><strong>Rules dominate</strong>: complex routing rules that evaluate frequently.</li>
  </ul>
  <p class="muted">
    Once you know the dominant driver, optimization becomes targeted instead of guesswork.
  </p>

  <h2>Sources</h2>
  <ul>
    <li>
      <a href="https://aws.amazon.com/elasticloadbalancing/pricing/" target="_blank" rel="nofollow noopener">
        Elastic Load Balancing pricing
      </a>
    </li>
  </ul>
</GuideLayout>
