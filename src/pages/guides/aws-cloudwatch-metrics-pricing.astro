---
import GuideLayout from "../../layouts/GuideLayout.astro";

const title = "CloudWatch metrics pricing: what to model (metrics + API + dashboards)";
const description =
  "A practical CloudWatch metrics pricing checklist: custom metric time series, high-cardinality dimensions, metrics API requests, dashboards, and alarms. Includes a fast modeling workflow and pitfalls.";
---
<GuideLayout
  title={title}
  description={description}
  canonicalPath="/guides/aws-cloudwatch-metrics-pricing"
  lastUpdated="2026-01-27"
  faqs={[
    {
      q: "What is the biggest driver for many CloudWatch metrics bills?",
      a: "Custom metrics and cardinality. Dimensions with many unique values multiply time series and can dominate cost.",
    },
    {
      q: "Do metrics API requests matter?",
      a: "They can. Dashboards and external tools polling frequently can add a meaningful request-based line item.",
    },
  ]}
>
  <p>
    CloudWatch metrics pricing often looks like "a few small line items" until metric sprawl and polling add up. A useful
    cost model separates <strong>metric volume</strong> (time series) from <strong>metric access</strong> (API requests
    and dashboards), and then adds <strong>alarms</strong> as a related bucket.
  </p>

  <h2>What to include in a metrics estimate</h2>
  <ul>
    <li>
      <strong>Custom metrics time series</strong>: metric names * dimension combinations * environments
    </li>
    <li>
      <strong>Resolution</strong>: standard vs high-resolution where applicable
    </li>
    <li>
      <strong>Metrics API requests</strong>: dashboard refresh + tooling polling
    </li>
    <li>
      <strong>Dashboards</strong>: dashboard-month charges (and their polling effects)
    </li>
    <li>
      <strong>Alarms</strong>: alarm-months created from metrics (separate pricing bucket)
    </li>
  </ul>
  <div class="btn-row">
    <a class="btn" href="/calculators/cloudwatch-metrics-cost-calculator/">CloudWatch metrics cost</a>
    <a class="btn" href="/calculators/aws-cloudwatch-alarms-cost-calculator/">Alarms cost</a>
  </div>

  <h2>Fast modeling workflow</h2>
  <ol>
    <li>Estimate custom metric time series (baseline + growth scenario).</li>
    <li>Estimate metrics API requests from dashboards and tooling polling.</li>
    <li>Count dashboards and alarms (prod vs non-prod).</li>
    <li>Apply your region pricing and validate against a real week of usage.</li>
  </ol>

  <h2>How to estimate the two core drivers</h2>
  <ul>
    <li>
      <strong>Custom metrics</strong>: count time series and identify high-cardinality dimensions.
      Guide: <a href="/guides/aws-cloudwatch-metrics-estimate-custom-metrics/">estimate custom metrics</a>.
    </li>
    <li>
      <strong>API requests</strong>: model dashboard refresh and tool polling.
      Guide: <a href="/guides/aws-cloudwatch-metrics-estimate-api-requests/">estimate API requests</a>.
    </li>
  </ul>

  <h2>Worked example (why this grows fast)</h2>
  <p class="muted">
    Suppose you publish 30 metrics per service, each with 2 dimensions (service and status), and you have 12 services and
    2 environments. If status has 5 values, a rough series estimate is:
  </p>
  <ul>
    <li>Series ~= 30 * (12 * 5) * 2 ~= 3,600 series</li>
  </ul>
  <p class="muted">
    If you add a high-cardinality dimension (podId, tenantId), series can jump by orders of magnitude without any traffic
    increase.
  </p>

  <h2>Common pitfalls</h2>
  <ul>
    <li>Adding unbounded dimensions (tenantId, userId, podId) and creating runaway series counts.</li>
    <li>Copying full dashboard packs into every environment and keeping them forever.</li>
    <li>Multiple tools polling CloudWatch in parallel (duplicated API request volume).</li>
    <li>Publishing per-instance metrics when service-level aggregates would work for alerting.</li>
    <li>Not separating prod vs non-prod (non-prod is often the safest cost reduction).</li>
  </ul>

  <h2>Optimization direction</h2>
  <ul>
    <li>Control cardinality with a dimension budget and explicit review.</li>
    <li>Aggregate by default; use per-instance only for deep debugging.</li>
    <li>Reduce polling overlap and slow down refresh for slow-moving metrics.</li>
  </ul>
  <p class="muted">
    Guide: <a href="/guides/aws-cloudwatch-metrics-cost-optimization/">CloudWatch metrics cost optimization</a>.
  </p>

  <h2>Validation checklist</h2>
  <ul>
    <li>Measure active series by namespace and identify top dimensions.</li>
    <li>Measure API request volume for at least 7 days (include a busy/incident day if possible).</li>
    <li>Confirm dashboard time ranges and refresh intervals match the decision speed you need.</li>
    <li>Validate alarms: do you have many per-resource alarms that scale with fleet size?</li>
  </ul>

  <h2>Sources</h2>
  <ul>
    <li>
      CloudWatch pricing:{" "}
      <a href="https://aws.amazon.com/cloudwatch/pricing/" rel="nofollow noopener" target="_blank">
        aws.amazon.com/cloudwatch/pricing
      </a>
    </li>
  </ul>
</GuideLayout>

