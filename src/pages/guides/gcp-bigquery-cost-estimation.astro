---
import GuideLayout from "../../layouts/GuideLayout.astro";

const title = "BigQuery cost estimation: storage, bytes scanned, and the dashboard trap";
const description =
  "Estimate BigQuery-style analytics costs with measurable drivers: stored data (GB-month), bytes scanned (per query), and streaming/exports. Includes a workflow to model baseline vs peak and validate partition pruning and dashboard refresh behavior.";

const faqs = [
  {
    q: "What usually drives analytics warehouse costs?",
    a: "Bytes scanned (or slot usage) is often the biggest variable, while storage is the steady baseline. Inefficient queries, missing partition pruning, and dashboards refreshing frequently cause most surprises.",
  },
  {
    q: "How do I estimate quickly?",
    a: "Estimate stored GB and retention for storage, then estimate scanned TB/day for queries and scheduled jobs. Keep streaming ingestion and exports as separate line items.",
  },
  {
    q: "What is the most common cost mistake?",
    a: "Treating 'one dashboard' as free. Dashboards refreshing every minute can run 1,440 scans/day and dominate bytes processed.",
  },
  {
    q: "How do I validate?",
    a: "Validate partitioning/clustering and ensure common queries prune partitions. Validate dashboard refresh rates and scheduled jobs, and measure bytes processed for the top queries.",
  },
];
---
<GuideLayout
  title={title}
  description={description}
  canonicalPath="/guides/gcp-bigquery-cost-estimation"
  lastUpdated="2026-01-27"
  faqs={faqs}
>
  <p>
    Analytics warehouses are predictable when you treat them as three independent problems: <strong>storage</strong>,{" "}
    <strong>bytes processed (scans)</strong>, and <strong>data movement</strong> (streaming in and exporting out). Most teams
    miss by underestimating scans driven by dashboards and scheduled jobs.
  </p>

  <h2>0) Pick your cost drivers (what to measure)</h2>
  <ul>
    <li>
      <strong>Stored data</strong>: average GB stored across the month (and growth).
    </li>
    <li>
      <strong>Bytes processed</strong>: TB scanned/day by queries, dashboards, and scheduled jobs.
    </li>
    <li>
      <strong>Ingestion/exports</strong>: streaming ingestion volume and any cross-region/internet export transfer.
    </li>
  </ul>

  <h2>1) Storage (GB-month) and growth</h2>
  <p>
    Storage is the baseline. Use average GB across the month, and model growth if you retain daily partitions.
  </p>
  <p class="muted">
    Tool: <a href="/calculators/database-storage-growth-cost-calculator/">Storage growth model</a>.
  </p>
  <ul>
    <li>
      If you have daily partitions, average GB tends to rise unless you enforce retention and deletion.
    </li>
    <li>
      Separate raw tables from curated/derived tables; derived tables can double storage if you materialize aggressively.
    </li>
  </ul>

  <h2>2) Bytes processed (query scans)</h2>
  <p>
    For scan-priced analytics, the practical model is:
    <strong> TB/day scanned = sum over workloads(queries/day × TB/query)</strong>. Keep baseline and peak separately.
  </p>
  <p class="muted">
    Tool: <a href="/calculators/log-search-scan-cost-calculator/">Scan cost model</a> (same math: GB scanned × $/GB).
  </p>
  <ul>
    <li>
      <strong>Dashboards</strong>: refresh interval × number of panels × time window can dominate TB scanned.
    </li>
    <li>
      <strong>Scheduled jobs</strong>: hourly/daily jobs are often the largest consistent scanner.
    </li>
    <li>
      <strong>Peak month</strong>: incident investigations and ad-hoc analysis can multiply query volume.
    </li>
  </ul>

  <h2>3) Partitioning and clustering (the biggest lever)</h2>
  <p>
    Most scan overages happen because queries read more data than intended. Partitioning and clustering are the primary
    levers to reduce bytes processed.
  </p>
  <ul>
    <li>
      Validate that common queries filter on the partition key (so partitions prune).
    </li>
    <li>
      Avoid wide time windows by default (30–90 day dashboards scan huge datasets repeatedly).
    </li>
    <li>
      If you materialize derived tables, ensure they are not re-scanned unnecessarily.
    </li>
  </ul>

  <h2>4) Streaming ingestion and exports</h2>
  <p>
    If you stream events in, model ingestion as its own volume line item. If you export results frequently (to object storage,
    to another region, to external systems), model export transfer separately.
  </p>
  <p class="muted">
    Tools: <a href="/calculators/object-storage-cost-calculator/">Object storage</a>,{" "}
    <a href="/calculators/data-egress-cost-calculator/">Egress</a>.
  </p>

  <h2>Worked estimate template (copy/paste)</h2>
  <ul>
    <li>
      <strong>Stored GB-month</strong> = average stored GB (include growth and derived tables)
    </li>
    <li>
      <strong>Scanned TB/day</strong> = dashboards + scheduled jobs + ad-hoc queries (baseline + peak)
    </li>
    <li>
      <strong>Streaming ingest</strong> = events/day × bytes/event (if applicable)
    </li>
    <li>
      <strong>Exports</strong> = GB/month moved out (cross-region/internet)
    </li>
  </ul>

  <h2>Common pitfalls</h2>
  <ul>
    <li>Dashboards refreshing too frequently with wide time windows.</li>
    <li>Queries that do not prune partitions (scan explosion).</li>
    <li>Materializing derived tables without retention (storage doubles quietly).</li>
    <li>Not modeling ad-hoc investigations and incident analysis (peak month).</li>
    <li>Ignoring export/egress costs for large result sets.</li>
  </ul>

  <h2>How to validate</h2>
  <ul>
    <li>List top 10 queries/dashboards and measure bytes processed per run.</li>
    <li>Validate refresh intervals and panel counts (queries multiply fast).</li>
    <li>Validate partition pruning and clustering behavior on common filters.</li>
    <li>Validate storage growth and retention (raw + derived tables).</li>
  </ul>

  <h2>Related tools</h2>
  <div class="btn-row">
    <a class="btn" href="/calculators/database-storage-growth-cost-calculator/">Storage growth</a>
    <a class="btn" href="/calculators/log-search-scan-cost-calculator/">Scan model</a>
    <a class="btn" href="/calculators/data-egress-cost-calculator/">Egress</a>
    <a class="btn" href="/guides/cloud-cost-estimation-checklist/">Estimation checklist</a>
  </div>

  <h2>Sources</h2>
  <ul>
    <li>
      <a href="https://cloud.google.com/bigquery/pricing" target="_blank" rel="nofollow noopener">
        BigQuery pricing
      </a>
    </li>
    <li>
      <a href="https://cloud.google.com/bigquery/docs" target="_blank" rel="nofollow noopener">
        BigQuery documentation
      </a>
    </li>
  </ul>
</GuideLayout>

