---
import GuideLayout from "../../layouts/GuideLayout.astro";

const title = "Kubernetes requests vs limits: why requests drive node count (and cost)";
const description =
  "A practical explanation of Kubernetes requests vs limits for capacity planning and cost estimation, with common mistakes, a worked sizing workflow, and links to calculators.";

const faqs = [
  {
    q: "Why do requests drive node count?",
    a: "The scheduler places pods based on requests. When total requests exceed allocatable capacity, you need more nodes regardless of average usage.",
  },
  {
    q: "Are limits useless for sizing?",
    a: "No. Limits are useful for understanding burst risk and stability, but they are not the baseline input for node count unless the workload frequently runs near the limit.",
  },
  {
    q: "What is the most common mistake?",
    a: "Setting limits high and then treating limits as requests. That typically inflates node estimates and cost without improving reliability.",
  },
];
---
<GuideLayout
  title={title}
  description={description}
  canonicalPath="/guides/kubernetes-requests-vs-limits-for-sizing"
  lastUpdated="2026-02-07"
  faqs={faqs}
>
  <p>
    If you search for a <a href="/calculators/kubernetes-cost-calculator/">Kubernetes cost calculator</a>, you will quickly
    see "requests" and "limits". The short version: <strong>requests</strong> are what the scheduler uses for capacity
    planning; <strong>limits</strong> are guardrails for bursting and safety. Mixing them up often leads to oversized
    clusters (or unpredictable performance risk).
  </p>

  <h2>Sizing decision rules</h2>
  <ul>
    <li><strong>Requests</strong>: use for scheduling and node count.</li>
    <li><strong>Limits</strong>: use for burst control, not capacity.</li>
    <li><strong>Overhead</strong>: include daemonsets and system reserve.</li>
  </ul>


  <h2>Requests: the scheduling baseline</h2>
  <p>
    Requests are the resources a pod asks for. Kubernetes tries to ensure that capacity exists for the sum of requests on
    each node (plus overhead). That makes requests the right baseline for "how many nodes do I need?"
  </p>
  <ul>
    <li>CPU requests affect packing and scheduling decisions.</li>
    <li>Memory requests are often the real limiter because memory is not compressible the way CPU can be.</li>
  </ul>

  <h2>Limits: the ceiling (risk and stability)</h2>
  <p>
    Limits cap how much a container can use. CPU limits can cause throttling; memory limits can cause OOM kills. Limits
    affect performance and risk, but they are not used for scheduling capacity the same way requests are.
  </p>
  <ul>
    <li>If CPU limits are too low, p95 latency can spike when traffic bursts.</li>
    <li>If memory limits are too low, OOM churn can create retries, errors, and extra traffic.</li>
  </ul>

  <h2>Common mistakes (and how they inflate cost)</h2>
  <ul>
    <li>
      <strong>Using limits as requests</strong>: many teams set limits to 2-4x requests for burstability; treating that as a
      baseline inflates node estimates.
    </li>
    <li>
      <strong>Ignoring overhead</strong>: kube-system, daemonsets, and headroom reduce allocatable capacity.
    </li>
    <li>
      <strong>Assuming perfect packing</strong>: affinities, max pods/node, and topology spread constraints raise node count
      beyond the math minimum.
    </li>
    <li>
      <strong>Using peak traffic 24/7</strong>: plan baseline and peak as separate scenarios.
    </li>
  </ul>

  <h2>A simple sizing workflow</h2>
  <ol>
    <li>Pick representative requests (baseline month, not incident peak).</li>
    <li>Estimate total requests = pods x per-pod requests (CPU and memory).</li>
    <li>Apply allocatable % to node capacity (leave headroom for overhead).</li>
    <li>Compute node count from CPU and memory, then take the larger number.</li>
    <li>Add a peak scenario and compare the delta (autoscaling vs always-on capacity).</li>
  </ol>
  <p class="muted">
    Tool: <a href="/calculators/kubernetes-requests-limits-calculator/">Kubernetes Requests &amp; Limits Calculator</a>.
    Once you have node count, price it with{" "}
    <a href="/calculators/kubernetes-node-cost-calculator/">Kubernetes Node Cost</a>.
  </p>

  <h2>Related tools</h2>
  <div class="btn-row">
    <a class="btn" href="/calculators/kubernetes-requests-limits-calculator/">Requests &amp; limits sizing</a>
    <a class="btn" href="/calculators/kubernetes-node-cost-calculator/">Kubernetes node cost</a>
    <a class="btn" href="/guides/kubernetes-cost-calculator/">Kubernetes cost checklist</a>
  </div>

  <h2>Sources</h2>
  <ul>
    <li>
      <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/" target="_blank" rel="nofollow noopener">
        Kubernetes: resource requests and limits
      </a>
    </li>
    <li>
      <a href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/" target="_blank" rel="nofollow noopener">
        Kubernetes: node allocatable and reservations
      </a>
    </li>
  </ul>
</GuideLayout>

